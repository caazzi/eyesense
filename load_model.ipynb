{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706da888-f2cf-49e3-b9d8-7e36ce4f4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 16:28:04.083875: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 16:28:04.090846: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 16:28:04.125249: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-24 16:28:04.214995: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742833684.282518   83434 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742833684.296650   83434 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742833684.444805   83434 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742833684.444859   83434 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742833684.444863   83434 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742833684.444865   83434 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 16:28:04.474916: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers # type: ignore\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory # type: ignore\n",
    "import pathlib\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score, cohen_kappa_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af275a2-be6d-42e8-8f1d-8268d3b5fb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 451 files belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1742833693.651781   83434 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1742833693.843906   83434 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâThe shape of each test batch is (32, 299, 299, 3)\n",
      "  The shape of each target batch is (32,)\n",
      "üëÄ The classes that was used for training the model are:\n",
      "- cataract\n",
      "- degeneration\n",
      "- diabets\n",
      "- glaucoma\n",
      "- hypertension\n",
      "- myopia\n",
      "- normal\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 299\n",
    "img_width  = 299\n",
    "\n",
    "#Adjust the path according to your machine\n",
    "data_dir_test  = pathlib.Path('raw_data/data_test/')\n",
    "\n",
    "\n",
    "test_ds = image_dataset_from_directory(\n",
    "            data_dir_test,\n",
    "            image_size=(img_height, img_width),\n",
    "            batch_size=batch_size)\n",
    "\n",
    "for image_batch, labels_batch in test_ds:\n",
    "  print(f\"üëâThe shape of each test batch is {image_batch.shape}\")\n",
    "  print(f\"  The shape of each target batch is {labels_batch.shape}\")\n",
    "  break\n",
    "\n",
    "print(\"üëÄ The classes that was used for training the model are:\")\n",
    "for name in test_ds.class_names:\n",
    "    print(f\"- {name}\")\n",
    "\n",
    "num_classes = len(test_ds.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a95550f-814b-456d-b586-0d852b33c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "#Normalization of the image tensors\n",
    "normalization_layer =   layers.Rescaling(1./255)\n",
    "normalized_test_ds  =  test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaa457-1b6a-42cb-85ae-5cd1d771dfd6",
   "metadata": {},
   "source": [
    "# Let's test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6533ca2-8ce5-4468-9534-7de12cd43c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/.pyenv/versions/3.10.6/envs/eyesense/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 9 variables whereas the saved optimizer has 1 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "#### # Load the model\n",
    "model = model = tf.keras.models.load_model(\"raw_data/Xception-01.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7fa310a-44aa-4deb-8f26-fc46f200229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(normalized_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07778843-f023-4b27-8ea5-ac32df0c0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 16:28:48.370948: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true = np.concatenate([y.numpy() for _, y in normalized_test_ds], axis=0)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4549f9ba-c6be-4cb5-b43f-4695f9dfb8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cataract',\n",
       " 'degeneration',\n",
       " 'diabets',\n",
       " 'glaucoma',\n",
       " 'hypertension',\n",
       " 'myopia',\n",
       " 'normal']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ee78a-9895-4ae5-ab7b-b3fbeb9487d6",
   "metadata": {},
   "source": [
    "# AUC for multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44aafae0-0389-4714-8046-48c0c53a733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_true_one_hot = encoder.fit_transform(np.array(y_true).reshape(-1, 1))\n",
    "y_true_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf4501b4-4642-4917-9276-f4f18d176cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC scores for each class: [np.float64(0.31623323852092644), np.float64(0.5427464008859357), np.float64(0.555219620743034), np.float64(0.5822208094935368), np.float64(0.5848072562358277), np.float64(0.5207852193995381), np.float64(0.5112710964239349)]\n"
     ]
    }
   ],
   "source": [
    "n_classes = y_true_one_hot.shape[1]  # Number of classes\n",
    "auc_scores = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    auc = roc_auc_score(y_true_one_hot[:, i], np.array(y_pred_prob)[:, i], multi_class='ovo')\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "print(f\"AUC scores for each class: {auc_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8789d-a936-4320-a70c-a4566116ac3d",
   "metadata": {},
   "source": [
    "# See other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f58fb1-837a-4c31-b89d-5cd5962fb620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class                accuracy   recall      f1_score   precision  roc_auc   \n",
      "cataract             0.89       0.47        0.47       0.47       0.47      \n",
      "degeneration         0.92       0.53        0.53       0.53       0.53      \n",
      "diabets              0.69       0.53        0.51       0.56       0.53      \n",
      "glaucoma             0.87       0.52        0.51       0.51       0.52      \n",
      "hypertension         0.96       0.49        0.49       0.49       0.49      \n",
      "myopia               0.92       0.51        0.51       0.51       0.51      \n",
      "normal               0.52       0.52        0.51       0.52       0.52      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = [['class','accuracy', 'recall', 'f1_score', 'precision', \"roc_auc\"] ]\n",
    "for class_id in range(7):\n",
    "    class_y_true = [1 if label == class_id else 0 for label in y_true]\n",
    "    class_y_pred = [1 if pred  == class_id else 0 for pred in y_pred ]\n",
    "    \n",
    "    class_recall    = recall_score(class_y_true, class_y_pred, average = 'macro')\n",
    "\n",
    "    class_accuracy  = accuracy_score(class_y_true, class_y_pred)\n",
    "    \n",
    "    class_f1        = f1_score(class_y_true, class_y_pred, average = 'macro')\n",
    "\n",
    "    class_precision = precision_score(class_y_true, class_y_pred, average = 'macro')\n",
    "\n",
    "    #class_auc = auc_scores[class_id]\n",
    "    class_auc = roc_auc_score(class_y_true, class_y_pred, average = 'macro')\n",
    "\n",
    "    results.append([test_ds.class_names[class_id], class_accuracy, class_recall, class_f1, class_precision, class_auc])\n",
    "\n",
    "print(\"{:<20} {:<10} {:<10}  {:<10} {:<10} {:<10}\".format(*results[0]))\n",
    "\n",
    "for row in results[1:]:\n",
    "    print(\"{:<20} {:<10.2} {:<10.2}  {:<10.2} {:<10.2} {:<10.2}\".format(*row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2bb983-5edd-440f-929c-67bb7339eddc",
   "metadata": {},
   "source": [
    "Given that our model has a high accuracy for amolst all classes, it is able to classify some instances. However, it's important to consinder that the dataset is imbalanced. When we look at the results for other metrics, we can see that the model is very close to the baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da541c-5e21-4306-adf8-733cfd5ee172",
   "metadata": {},
   "source": [
    "# We don't need to upload the test dataset to the clouds. We can create a dict by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "556c51bb-cc07-4c0f-89be-27cf35a2d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict = {0: 'cataract', 1 :'degeneration', 2:'diabets', 3: 'glaucoma', 4: 'hypertension', 5:'myopia', 6:'normal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a3e9184-082c-4104-91f7-2ade145a1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load an image and resize it to the model's expected input size (e.g., 299x299 for Xception)\n",
    "image = load_img(\"raw_data/data_test/glaucoma/1365_right.jpg\", target_size=(299, 299))  # glaucoma image\n",
    "image_array_norm = img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
    "image_array = np.expand_dims(image_array_norm, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd60f5e8-0e5c-446d-9ad8-58717b16968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d99bdb-401a-44ba-8db8-d2d431e37505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2466382e-02, 1.3366773e-03, 4.8659969e-02, 6.9714057e-01,\n",
       "        4.3341835e-04, 1.9818561e-05, 2.2994313e-01]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07bd2e1a-460e-41c6-94be-30c6de812b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_id = np.argmax(pred, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43497272-99c4-46a5-ac26-095bc9e3224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glaucoma'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict[pred_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
